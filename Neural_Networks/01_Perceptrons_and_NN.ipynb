{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptrons\n",
    "---\n",
    "\n",
    "- It is a type of artificial neuron, developed in the 50s by Frank Rosenblatt.\n",
    "- Used to understand **Sigmoid neurons**\n",
    "\n",
    "## Working"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Perceptrons take several binary inputs and produces a single output.\n",
    "- Rosenblatt introduced a simple rule to compute the output\n",
    "- **Weights** - w1, w2,... are real numbers expressing the importance of the respective inputs to the output.\n",
    "- The neuron's output 0 or 1 is determined by whether the weighted sum $\\sum_j w_j x_j$ is less than or greater than some threshold value (real number, parameter of the neuron).\n",
    "i.e.\n",
    "\n",
    "$\\begin{eqnarray}\n",
    "  \\mbox{output} & = & \\left\\{ \\begin{array}{ll}\n",
    "      0 & \\mbox{if } \\sum_j w_j x_j \\leq \\mbox{ threshold} \\\\\n",
    "      1 & \\mbox{if } \\sum_j w_j x_j > \\mbox{ threshold}\n",
    "      \\end{array} \\right.\n",
    "\\tag{1}\\end{eqnarray}\n",
    "$\n",
    "\n",
    "> It is a device that makes decisions by weighing up evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E.g - Let's say we want to go to the park, but there are certain conditions which could influence the decision.\n",
    "Such as - Is the weather good? Is the park closed? Are my friends going?\n",
    "We can represent these binary factors with inputs as x1, x2, x3.\n",
    "Now, when the perceptron tries to make decision we emphasize that the weather is probably the most important factor in our decision making process and thus we give it a large weight value. Also, a threshold is chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplify the notations -\n",
    "\n",
    "- The weighted sum is changed to a matrix dot product, $w \\cdot x \\equiv \\sum_j w_j x_j$. Here, w and x are vectors whose components are the weights and inputs. \n",
    "- Also, the threshold is moved to the other side of the inequality. and is replaced by the  perceptron **bias**. $b \\equiv -\\mbox{threshold}$\n",
    "\n",
    "The new rules are\n",
    "\n",
    "$\n",
    "   \\begin{eqnarray}\n",
    "  \\mbox{output} = \\left\\{ \n",
    "    \\begin{array}{ll} \n",
    "      0 & \\mbox{if } w\\cdot x + b \\leq 0 \\\\\n",
    "      1 & \\mbox{if } w\\cdot x + b > 0\n",
    "    \\end{array}\n",
    "  \\right.\n",
    "\\tag{2}\\end{eqnarray}\n",
    "$\n",
    "\n",
    "- Bias is a measure of how easy it is to get the perceptron to output a 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptrons can also be used to compute elementary logical functions such as AND, OR and NAND.\n",
    "\n",
    "Most interesting thing is when a **learning algorithm** can tune the weights and biases in response to external stimuli without direct intervention. It can learn to solve problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmoid Neurons\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Small change in some weight or bias in the network. It will cause the output to change slightly. This is what makes the learning algorithms possible.\n",
    "\n",
    "- We can modify the weights and biases using the above to get the network to behave more in the manner we want.\n",
    "- The problem with perceptrons is that changing a weight or bias can completely flip the neuron output. This could have very different affects in the rest of the network. So, it is very difficult to gradually modify the weights and biases so that the network gets closer to the desired behavior.\n",
    "- This problem is solved by using a new type of neuron called a **Sigmoid neuron**.\n",
    "- They are similar to perceptrons only modified so that small change in weight or bias causes a small change in their output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working\n",
    "\n",
    "Similar to a perceptron, it has inputs x1, x2,... but instead of binary they can take any value between 0 and 1. It also has weights for each input and an overall bias, b.\n",
    "Also, the output is not 0 or 1. Instead it is  $\\sigma(w \\cdot x+b)$, where $\\sigma$ is called the sigmoid function and is defined by\n",
    "$\\begin{eqnarray} \n",
    "  \\sigma(z) \\equiv \\frac{1}{1+e^{-z}}.\n",
    "\\end{eqnarray}$\n",
    "\n",
    "Therefore, the outputs of sigmoid neuron is $\\begin{eqnarray} \n",
    "\\frac{1}{1+\\exp(-\\sum_j w_j x_j-b)}.\n",
    "\\end{eqnarray}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity to the perceptron model\n",
    "\n",
    "Suppose $z \\equiv w \\cdot x + b$ is a large positive value. Then $ e^{-z}\\approx 0 $ and so $\\sigma(z) \\approx 1$. If $z$ is large and positive, output of sigmoid neuron is 1, same like perceptrons. Similarly if $z$ is very negative, then $e^{-z} \\rightarrow \\infty$ and $\\sigma(z) \\approx 0$. Same as perceptrons.\n",
    "When the size of $z$ increases there's more deviation from the perceptron model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sigmoid function is a smoothed out version of step function. If $\\sigma$ becomes a step function, then the sigmoid neuron will become a perceptron model.\n",
    "- The smoothness of the sigmoid function is of importance. It means that small changes $\\Delta w_j$ in the weights and $\\Delta b$ in the bias will produce a small change $\\Delta output$ in the output from the neuron.\n",
    "- Calculus tells us that\n",
    "$\\begin{eqnarray} \n",
    "  \\Delta \\mbox{output} \\approx \\sum_j \\frac{\\partial \\, \\mbox{output}}{\\partial w_j}\n",
    "  \\Delta w_j + \\frac{\\partial \\, \\mbox{output}}{\\partial b} \\Delta b,\n",
    "\\end{eqnarray}$. It is saying that $\\Delta output$ is a linear function of changes in $w$ and $b$. This linearity makes it easy to choose small changes in the weights and biases to achieve any desired small change in output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Architecture of neural networks\n",
    "---\n",
    "- A NN can do a pretty good job of classifying handwritten digits.\n",
    "- Leftmost layer is a NN is called input layer.\n",
    "- Rightmost layer is called output layer.\n",
    "- Middle layers are called Hidden layers, neither inputs nor outputs.\n",
    "- For historical reasons, multi layer networks are sometimes called as multilayer perceptrons or MLPs, despite comprising of sigmoid neurons.\n",
    "- Output of one layer is used as input to the next layer. Such networks are called *feedforward* NN. No loops in the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple network to classify handwritten digits\n",
    "---\n",
    "\n",
    "This problem could be split into two sub-problems.\n",
    "\n",
    "- First, way of breaking an image containing many digits ionto sequence of separate images, each containing a single digit.\n",
    "- Second, classify the digit.\n",
    "- To recognize individual digits we will use a **three layer NN**.\n",
    "- Training Data for the network will consist of 28 X 28 pixel images of scanned handwritten digits. So, the input layer will contain 784 neurons.\n",
    "- Input pixels are greyscale, 0.0 representing white and 1.0 black.\n",
    "- Number of neurons in the one hidden layer is $n$. Here $n = 15$.\n",
    "- The output layer of the network contains 10 neurons. If first neuron fires i.e. output $\\approx 1$, then that will indicate that the network thinks the digit is 0. If second neuron fires, then digit is a 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning with gradient descent\n",
    "---\n",
    "\n",
    "About the MNIST dataset --\n",
    "\n",
    "- It comes in two parts. First part contains 60,000 images to be part of training set. Second part contains 10,000 images used as test data.\n",
    "- Handwriting samples from 250 people. Greyscale images of 28 X 28 pixels in size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $x$ to denote a training input. Each $x$ is a 784 dimensional vector.\n",
    "- Corresponding output $y = y(x)$. Here $y$ is a 10-dim vector.\n",
    "E.g - If x = 6, then $y(x) = (0,0,0,0,0,0,1,0,0,0)^{T}$ is the desired output from the network.\n",
    "- An algorithm which would help us to find weights and biases so that the output from the network approximates $y(x)$ for all x. --> Define a **Cost function.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function (Mean Squared Error or MSE)\n",
    "\n",
    "$\\begin{eqnarray}  C(w,b) \\equiv\n",
    "  \\frac{1}{2n} \\sum_x \\| y(x) - a\\|^2.\n",
    "\\tag{A}\\end{eqnarray}$\n",
    "\n",
    "Eq. A is called the loss or objective function.\n",
    "Here, w denotes the collection of all weights in the network, b all the biases, n is total number of training inputs, a is the vector of all outputs from the network when x is input and the sum is over all the training inputs.\n",
    "\n",
    "### Cost function analyses\n",
    "\n",
    "- $C(w, b)$ is non-negative, and $C(w, b) \\approx 0$, when $y(x)$ is equal to output $a$.\n",
    "- So, the training algorithm has done a good job if it can find weights and biases so that C is approx. 0.\n",
    "- If it is large, network is performing badly.\n",
    "- We have to find min. $C(w, b)$. We use **Gradient Descent**. We cannot use calculus because if number of variables is very large it becomes very hard to minimize it.\n",
    "\n",
    "- Why use a const function and not directly maximize the number. Since, number of images correctly classified is not a smooth function of w and b, small changes to them won't cause any change at all in the number of images classified correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "---\n",
    "- Like a ball rolling down the slope in a valley. The ball will eventually roll to the bottom of the valley.\n",
    "- when we move the ball a small amount Δv1 in the v1 direction, and a small amount Δv2 in the v2 direction. Then, $\\begin{eqnarray} \n",
    "  \\Delta C \\approx \\frac{\\partial C}{\\partial v_1} \\Delta v_1 +\n",
    "  \\frac{\\partial C}{\\partial v_2} \\Delta v_2.\n",
    "\\end{eqnarray}$\n",
    "- We have to find a way of choosing $\\Delta v_1$ and $\\Delta v_2$ so as to make $\\Delta C$ negative, i.e. so that the ball is rolling down into the valley. $\\Delta v$ to be a vector of changes in v, $\\Delta v \\equiv (\\Delta v_1, \\Delta v_2)^T$.\n",
    "- Gradient of C to be the vector of partial derivatives, $\\left(\\frac{\\partial C}{\\partial v_1}, \\frac{\\partial C}{\\partial v_2}\\right)^T$.\n",
    "- We denote the gradient vector by $\\begin{eqnarray} \n",
    "  \\nabla C \\equiv \\left( \\frac{\\partial C}{\\partial v_1}, \n",
    "  \\frac{\\partial C}{\\partial v_2} \\right)^T.\n",
    "\\end{eqnarray}$\n",
    "- Then, $\\begin{eqnarray} \\Delta C \\approx \\nabla C \\cdot \\Delta v. \\end{eqnarray}$ This equation helps explain why it is called a gradient vector, since it relates changes in v to changes in C. It then let's us choose $\\Delta v$ so as to make $\\Delta C$ negative.\n",
    "- $\\begin{eqnarray} \\Delta v = -\\eta \\nabla C, \\end{eqnarray}$ $\\eta$ is called the learning rate, which is a small positive parameter.\n",
    "- Then, $\\Delta C \\approx -\\eta \\nabla C \\cdot \\nabla C = -\\eta \\|\\nabla C\\|^2$. It guarantees that $\\Delta C \\leq 0$ will always decrease.\n",
    "- $\\begin{eqnarray} v \\rightarrow v' = v -\\eta \\nabla C. \\end{eqnarray}$. This could be used as an update rule over and over again untill we hopefully reach global minimin.\n",
    "- Now, if C is function of many variable, then the change in C produced by small change in $\\Delta v = (\\Delta v_1, \\ldots, \\Delta v_m)^T$ is $\\begin{eqnarray} \\Delta C \\approx\\nabla C \\cdot \\Delta v,\\end{eqnarray}$ , where the $\\nabla C$ is the vector $\\begin{eqnarray} \\nabla C \\equiv \\left(\\frac{\\partial C}{\\partial v_1}, \\ldots, \\frac{\\partial C}{\\partial v_m}\\right)^T.\\end{eqnarray}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent in neural network\n",
    "\n",
    "- The idea is to find the weights $w_k$ and biases $b_l$ which minimize the cost function. Now, gradient vector has the following components $\\partial C / \\partial w_k$ and $\\partial C / \\partial b_l$.\n",
    "- The update rules are as follows \n",
    "\n",
    "$\\begin{eqnarray}\n",
    "  w_k & \\rightarrow & w_k' = w_k-\\eta \\frac{\\partial C}{\\partial w_k}\\\\\n",
    "  b_l & \\rightarrow & b_l' = b_l-\\eta \\frac{\\partial C}{\\partial b_l}.\n",
    "\\end{eqnarray}$\n",
    "\n",
    "- Since we have to compute the gradient for each training input and then average it, it can be slow when inputs is very large. So, we use **stochastic gradient descent**.\n",
    "- The idea is to estimate the gradient for a small sample of radomly chosen training inputs and averaging over this small sample.\n",
    "- Stochastic gradient descent works by randomly picking out a small number m of randomly chosen training inputs. We'll label those random training inputs X1,X2,…,Xm, and refer to them as a mini-batch. Provided the sample size m is large enough we expect that the average value of the $\\nabla C_{x_j} $ will be roughly equal to the average over all $\\nabla C_x$.\n",
    "$\\begin{eqnarray}\n",
    "  \\frac{\\sum_{j=1}^m \\nabla C_{X_{j}}}{m} \\approx \\frac{\\sum_x \\nabla C_x}{n} = \\nabla C,\n",
    "\\end{eqnarray}$\n",
    "- Then, $\\begin{eqnarray}\n",
    "  \\nabla C \\approx \\frac{1}{m} \\sum_{j=1}^m \\nabla C_{X_{j}},\n",
    "\\end{eqnarray}$\n",
    "- To connect explicitely, $\\begin{eqnarray} \n",
    "  w_k & \\rightarrow & w_k' = w_k-\\frac{\\eta}{m}\n",
    "  \\sum_j \\frac{\\partial C_{X_j}}{\\partial w_k} \\tag{B}\\\\\n",
    "  b_l & \\rightarrow & b_l' = b_l-\\frac{\\eta}{m}\n",
    "  \\sum_j \\frac{\\partial C_{X_j}}{\\partial b_l},\n",
    "\\tag{C}\\end{eqnarray}$\n",
    "- Where the sums are over all the training examples Xj in the current mini-batch. Then we pick out another randomly chosen mini-batch and train with those. And so on, until we've exhausted the training inputs, which is said to complete an **epoch** of training. At that point we start over with a new training epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
