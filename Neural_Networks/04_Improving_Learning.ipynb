{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving neural network learning\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The cross-entropy cost function\n",
    "---\n",
    "> We learn slowly when our errors are less well-defined.\n",
    "\n",
    "**Origin of slow learning** - If the input values to the neuron are too large or too small, then the sigmoid function curve gets very flat, so the derivative of sigma gets very small.\n",
    "This can be solved by using a different cost function rather than the quadratic cost function.\n",
    "\n",
    "The cross-entropy function is defined as \n",
    "$\n",
    "\\begin{eqnarray} \n",
    "  C = -\\frac{1}{n} \\sum_x \\left[y \\ln a + (1-y ) \\ln (1-a) \\right],\n",
    "\\tag{A}\\end{eqnarray}\n",
    "$\n",
    "where n is the total number of training data, sum over all the training inputs, x and output y.\n",
    "\n",
    "Cross-entropy as cost function --\n",
    "\n",
    "- Non-negative - All individual terms are negative, since the `log` is in range of 0 to 1. There is also the negative sign out front.\n",
    "- If the actual output is close to desired output for all training inputs, $C \\approx 0$\n",
    "\n",
    "$C$ tends towards zero as the neuron gets better at computing the desired output. It has the benifit over quadratic cost function that it avoids the slow learning problem.\n",
    "\n",
    "When we use cross entropy cost function,  $\\sigma'(z)$ gets canceled out so slow learning will not be a problem.\n",
    "\n",
    "\n",
    "The cost function for all the neurons in the output layer\n",
    "$\n",
    "\\begin{eqnarray}  C = -\\frac{1}{n} \\sum_x\n",
    "  \\sum_j \\left[y_j \\ln a^L_j + (1-y_j) \\ln (1-a^L_j) \\right].\n",
    "\\tag{B}\\end{eqnarray}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
